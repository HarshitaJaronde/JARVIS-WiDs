{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eeef5b0-adac-4cab-a81d-005140aa423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cf3ae8e-cb68-4aaa-afcd-938a0010f7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The extracted phone-numbers are:['(123) 456-7899', '444-333-2345']\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"This script can extract all phone numbers of format (123) 456-7899 or\n",
    "444-333-2345\"\"\"\n",
    "\n",
    "script = \"\\(\\d{3}\\) \\d{3}-\\d{4}|\\d{3}-\\d{3}-\\d{4}\"\n",
    "\n",
    "print(f' The extracted phone-numbers are:{re.findall(script,text)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce61457a-f17c-4a4f-8fb3-51453e53d97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SpaCy : False\n",
      " is : False\n",
      " a : False\n",
      " powerful : False\n",
      " NLP : False\n",
      " library : False\n",
      " for : False\n",
      " tokenization : False\n",
      " . : False\n",
      "   : True\n"
     ]
    }
   ],
   "source": [
    "#Question 2\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc1 = nlp( \"SpaCy is a powerful NLP library for tokenization.\")\n",
    "doc2 = nlp(\" \")\n",
    "for token in doc1:\n",
    "    print(f' {token} : {token.is_space}')\n",
    "for token in doc2:\n",
    "    print(f' {token} : {token.is_space}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13302141-5e7d-45d2-86d2-ed0094402b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner', 'token_count']\n"
     ]
    }
   ],
   "source": [
    "#Question 3\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "@Language.component(\"no_of_tokens_component\")\n",
    "def count_tokens(doc):\n",
    "    \n",
    "    doc.set_extension(\"no_of_tokens_component\", getter=lambda doc: len(doc))\n",
    "    return doc\n",
    "nlp.add_pipe(\"no_of_tokens_component\",name = 'token_count', last = True)\n",
    "\n",
    "print(nlp.pipe_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ba8029c-e0bc-42b2-92fb-fc0e28abfbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of tokens are: 9\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Customizing a SpaCy pipeline can be very useful.\")\n",
    "print(\"The number of tokens are:\", doc._.no_of_tokens_component)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ada55d7d-e46e-4be5-aad1-eabc8ed652f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP | proper noun | nsubj\n",
      "is | auxiliary | ROOT\n",
      "fascinating | adjective | acomp\n",
      ", | punctuation | punct\n",
      "and | coordinating conjunction | cc\n",
      "SpaCy | proper noun | nsubj\n",
      "makes | verb | conj\n",
      "it | pronoun | nsubj\n",
      "even | adverb | advmod\n",
      "more | adverb | advmod\n",
      "interesting | adjective | ccomp\n",
      ". | punctuation | punct\n"
     ]
    }
   ],
   "source": [
    "#Question 4\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp( \"NLP is fascinating, and SpaCy makes it even more interesting.\")\n",
    "for token in doc:\n",
    "    print( token,'|', spacy.explain(token.pos_),'|', token.dep_)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f56b90cc-33d3-44c7-8e4f-a4c54b37b22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elon Musk | PERSON | People, including fictional\n",
      "Tesla | ORG | Companies, agencies, institutions, etc.\n",
      "June 28, 1971 | DATE | Absolute or relative dates or periods\n",
      "Pretoria | GPE | Countries, cities, states\n",
      "South Africa | GPE | Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "#Question 5\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp( \"Elon Musk, the CEO of Tesla, was born on June 28, 1971, in Pretoria, South Africa.\")\n",
    "for ent in doc.ents:\n",
    "    print( ent,\"|\", ent.label_ ,\"|\", spacy.explain(ent.label_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38840138-f41d-4837-8477-b1ffd12f4691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0 0 0 0 1]\n",
      " [0 1 1 1 1 1 1 1]]\n",
      "['amazing' 'data' 'is' 'learning' 'machine' 'of' 'part' 'science']\n"
     ]
    }
   ],
   "source": [
    "#Question 6\n",
    "#bag of words vector\n",
    "corpus = [\"Data science is amazing\", \"Machine learning is part of data science\"] \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "v = CountVectorizer()\n",
    "corpus_cv = v.fit_transform(corpus)\n",
    "print(corpus_cv.toarray())\n",
    "print(v.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0eef264-3ac3-4a80-a2c0-7058d44caffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]]\n",
      "[[0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n",
      "['data' 'is' 'learning' 'machine' 'of' 'part' 'science']\n"
     ]
    }
   ],
   "source": [
    "#One Hot Encoding Vector\n",
    "corpus = [\"Data science is amazing\", \"Machine learning is part of data science\"] \n",
    "s1 = corpus[0].split()\n",
    "s2 = corpus[1].split()\n",
    "s1_cv = v.fit_transform(s1)\n",
    "s2_cv = v.fit_transform(s2)\n",
    "print(s1_cv.toarray())\n",
    "print(s2_cv.toarray())\n",
    "print(v.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "913d4d7f-6ae0-48aa-8a53-fd9c03d70fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.63009934 0.44832087 0.44832087 0.         0.         0.\n",
      "  0.         0.44832087]\n",
      " [0.         0.30287281 0.30287281 0.42567716 0.42567716 0.42567716\n",
      "  0.42567716 0.30287281]]\n",
      "['amazing' 'data' 'is' 'learning' 'machine' 'of' 'part' 'science']\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Vector\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\"Data science is amazing\", \"Machine learning is part of data science\"] \n",
    "v = TfidfVectorizer()\n",
    "vector = v.fit_transform(corpus)\n",
    "print(vector.toarray())\n",
    "print(v.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c82c04b-1c48-4277-ab7e-483ccb41a8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy-env-30-12-2024",
   "language": "python",
   "name": "spacy-env-30-12-2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
